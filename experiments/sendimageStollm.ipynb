{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de977d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nisha\\Coding\\NotesAssistant\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "import base64\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5967e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model= \"gemini-2.0-flash\",\n",
    "    convert_system_message_to_human=True,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0064d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_llm(image_file_path):\n",
    "    with open(image_file_path, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "    encoded_image = base64.b64encode(image_data).decode('utf-8')\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": \"Describe the image I am sending. Send it as plain text in paragraphs with no formatting\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_image}\"}\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = llm.invoke([message])\n",
    "    parsed_response = output_parser.invoke(response)\n",
    "    return (response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2da25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),  # Try 3 times\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=10),  # Wait between 4-10 seconds, increasing exponentially\n",
    ")\n",
    "def img_to_llm(image_file_path):\n",
    "    try:\n",
    "        with open(image_file_path, \"rb\") as image_file:\n",
    "            image_data = image_file.read()\n",
    "        encoded_image = base64.b64encode(image_data).decode('utf-8')\n",
    "        output_parser = StrOutputParser()\n",
    "\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"Describe the image I am sending. Send it as plain text in paragraphs with no formatting\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{encoded_image}\"}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        response = llm.invoke([message])\n",
    "        parsed_response = output_parser.invoke(response)\n",
    "        return response.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Attempt failed: {str(e)}\")\n",
    "        raise  # This will trigger the retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f517aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './output_images'\n",
    "for i in range(5):\n",
    "    llm_output = \"\"\n",
    "    image_filename = os.path.join(output_path,f'page_{i+1:03}.png')\n",
    "    llm_output = img_to_llm(image_filename)\n",
    "    text_filename = os.path.join(output_path, f'page_{i+1:03}.txt')\n",
    "    with open(text_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(llm_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e462eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nisha\\Coding\\NotesAssistant\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nisha\\.cache\\huggingface\\hub\\models--BAAI--bge-base-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# Define the model and its settings\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cuda'}  # If you want to use GPU (CUDA)\n",
    "encode_kwargs = {'normalize_embeddings': True}  # For cosine similarity\n",
    "\n",
    "# Create the embeddings object\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,  # You can change this for different tasks\n",
    "    query_instruction = \"Represent this sentence for answering questions:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d7dadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter()\n",
    "file_names = sorted([f for f in os.listdir(output_path) if f.endswith('.txt')])\n",
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961e43ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in file_names:\n",
    "    with open(os.path.join(output_path, file_name), 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    chunks = splitter.split_text(text)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        documents.append(Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\"source\": file_name, \"chunk_id\": i}\n",
    "        ))\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a281cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Use the following context to answer the question at the end. \n",
    "Answer in paragraphs with no formatting. Headings can be shown with the help of colons.\n",
    "If the answer is not in the context, just say \"I don't know\"â€” do not make anything up.\n",
    "If the answer is in the context and the user specifies the statement \"AOFS\" which stands for \"Answer only from slides\" do not provide any other information other than what is in the context.\n",
    "In the event user does not specify that statement and If the answer is in the context, Explain the context using your own knowledge of that subject, it doesn't have to be in the context.\n",
    "Also include a fun explanation to the concept using different analogies.\n",
    "Finally, include a very brief intuitive explanation which helps me get the basic intution of what's going on.\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{input}\n",
    "\n",
    "Answer:\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2bbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4993ccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":Synchronous vs. Asynchronous Data Transfer:\n",
      "\n",
      "Synchronous data transfer involves the transfer of data between two devices on a network where they both operate based on a common clock pulse. This means that the sender and receiver are synchronized by a shared timing signal, ensuring that data is transmitted and received at predictable intervals.\n",
      "\n",
      "Asynchronous data transfer, on the other hand, involves the transfer of data between two devices on a network where they operate based on a private clock pulse. In this method, the sender and receiver do not rely on a shared clock signal. Instead, the data transmission is often accompanied by start and stop bits, which signal the beginning and end of each data unit, allowing the receiver to synchronize with the data stream for each individual transmission.\n",
      "\n",
      ":Explanation with Analogies:\n",
      "\n",
      "Imagine a marching band (synchronous) where everyone steps in perfect unison because they're all following the same drumbeat (common clock pulse). The band members know exactly when to step because they all hear the same beat. Now, imagine a group of friends sending letters to each other (asynchronous). Each person writes and sends a letter whenever they want, and they don't need to coordinate with each other. Each letter includes an \"opening\" (start bit) and a \"closing\" (stop bit) so the receiver knows when the letter begins and ends.\n",
      "\n",
      ":Intuitive Explanation:\n",
      "\n",
      "Synchronous transfer is like a perfectly timed dance where everyone knows exactly when to move. Asynchronous transfer is like sending individual messages where each message has its own signal to say \"here I am\" and \"I'm done now.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\":\"Describe the difference between Synchronous and Asyncrhonous data transfer.\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
